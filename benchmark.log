Some weights of LlamaSkipConnectionForCausalLM were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B-Instruct and are newly initialized: ['model.layers.0.mlp.combined_proj_buffer', 'model.layers.0.mlp.down_proj_buffer', 'model.layers.0.mlp_lora_proj.down.weight', 'model.layers.0.mlp_lora_proj.intermediate', 'model.layers.0.mlp_lora_proj.output', 'model.layers.0.mlp_lora_proj.up.weight', 'model.layers.0.mlp_mask', 'model.layers.1.mlp.combined_proj_buffer', 'model.layers.1.mlp.down_proj_buffer', 'model.layers.1.mlp_lora_proj.down.weight', 'model.layers.1.mlp_lora_proj.intermediate', 'model.layers.1.mlp_lora_proj.output', 'model.layers.1.mlp_lora_proj.up.weight', 'model.layers.1.mlp_mask', 'model.layers.10.mlp.combined_proj_buffer', 'model.layers.10.mlp.down_proj_buffer', 'model.layers.10.mlp_lora_proj.down.weight', 'model.layers.10.mlp_lora_proj.intermediate', 'model.layers.10.mlp_lora_proj.output', 'model.layers.10.mlp_lora_proj.up.weight', 'model.layers.10.mlp_mask', 'model.layers.11.mlp.combined_proj_buffer', 'model.layers.11.mlp.down_proj_buffer', 'model.layers.11.mlp_lora_proj.down.weight', 'model.layers.11.mlp_lora_proj.intermediate', 'model.layers.11.mlp_lora_proj.output', 'model.layers.11.mlp_lora_proj.up.weight', 'model.layers.11.mlp_mask', 'model.layers.12.mlp.combined_proj_buffer', 'model.layers.12.mlp.down_proj_buffer', 'model.layers.12.mlp_lora_proj.down.weight', 'model.layers.12.mlp_lora_proj.intermediate', 'model.layers.12.mlp_lora_proj.output', 'model.layers.12.mlp_lora_proj.up.weight', 'model.layers.12.mlp_mask', 'model.layers.13.mlp.combined_proj_buffer', 'model.layers.13.mlp.down_proj_buffer', 'model.layers.13.mlp_lora_proj.down.weight', 'model.layers.13.mlp_lora_proj.intermediate', 'model.layers.13.mlp_lora_proj.output', 'model.layers.13.mlp_lora_proj.up.weight', 'model.layers.13.mlp_mask', 'model.layers.14.mlp.combined_proj_buffer', 'model.layers.14.mlp.down_proj_buffer', 'model.layers.14.mlp_lora_proj.down.weight', 'model.layers.14.mlp_lora_proj.intermediate', 'model.layers.14.mlp_lora_proj.output', 'model.layers.14.mlp_lora_proj.up.weight', 'model.layers.14.mlp_mask', 'model.layers.15.mlp.combined_proj_buffer', 'model.layers.15.mlp.down_proj_buffer', 'model.layers.15.mlp_lora_proj.down.weight', 'model.layers.15.mlp_lora_proj.intermediate', 'model.layers.15.mlp_lora_proj.output', 'model.layers.15.mlp_lora_proj.up.weight', 'model.layers.15.mlp_mask', 'model.layers.2.mlp.combined_proj_buffer', 'model.layers.2.mlp.down_proj_buffer', 'model.layers.2.mlp_lora_proj.down.weight', 'model.layers.2.mlp_lora_proj.intermediate', 'model.layers.2.mlp_lora_proj.output', 'model.layers.2.mlp_lora_proj.up.weight', 'model.layers.2.mlp_mask', 'model.layers.3.mlp.combined_proj_buffer', 'model.layers.3.mlp.down_proj_buffer', 'model.layers.3.mlp_lora_proj.down.weight', 'model.layers.3.mlp_lora_proj.intermediate', 'model.layers.3.mlp_lora_proj.output', 'model.layers.3.mlp_lora_proj.up.weight', 'model.layers.3.mlp_mask', 'model.layers.4.mlp.combined_proj_buffer', 'model.layers.4.mlp.down_proj_buffer', 'model.layers.4.mlp_lora_proj.down.weight', 'model.layers.4.mlp_lora_proj.intermediate', 'model.layers.4.mlp_lora_proj.output', 'model.layers.4.mlp_lora_proj.up.weight', 'model.layers.4.mlp_mask', 'model.layers.5.mlp.combined_proj_buffer', 'model.layers.5.mlp.down_proj_buffer', 'model.layers.5.mlp_lora_proj.down.weight', 'model.layers.5.mlp_lora_proj.intermediate', 'model.layers.5.mlp_lora_proj.output', 'model.layers.5.mlp_lora_proj.up.weight', 'model.layers.5.mlp_mask', 'model.layers.6.mlp.combined_proj_buffer', 'model.layers.6.mlp.down_proj_buffer', 'model.layers.6.mlp_lora_proj.down.weight', 'model.layers.6.mlp_lora_proj.intermediate', 'model.layers.6.mlp_lora_proj.output', 'model.layers.6.mlp_lora_proj.up.weight', 'model.layers.6.mlp_mask', 'model.layers.7.mlp.combined_proj_buffer', 'model.layers.7.mlp.down_proj_buffer', 'model.layers.7.mlp_lora_proj.down.weight', 'model.layers.7.mlp_lora_proj.intermediate', 'model.layers.7.mlp_lora_proj.output', 'model.layers.7.mlp_lora_proj.up.weight', 'model.layers.7.mlp_mask', 'model.layers.8.mlp.combined_proj_buffer', 'model.layers.8.mlp.down_proj_buffer', 'model.layers.8.mlp_lora_proj.down.weight', 'model.layers.8.mlp_lora_proj.intermediate', 'model.layers.8.mlp_lora_proj.output', 'model.layers.8.mlp_lora_proj.up.weight', 'model.layers.8.mlp_mask', 'model.layers.9.mlp.combined_proj_buffer', 'model.layers.9.mlp.down_proj_buffer', 'model.layers.9.mlp_lora_proj.down.weight', 'model.layers.9.mlp_lora_proj.intermediate', 'model.layers.9.mlp_lora_proj.output', 'model.layers.9.mlp_lora_proj.up.weight', 'model.layers.9.mlp_mask']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Configuring for 8 CPU threads
Model device: cpu
Input IDs device: cpu
Attention Mask device: cpu
Running CPU inference benchmarks...
--------------------------------------------------
Warming up models...

Model type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>
Model dtype: torch.float32

Model type: <class 'src.models.modelling_llama_skip.LlamaSkipConnectionForCausalLM'>
Model dtype: torch.float32

Model type: <class 'src.models.modelling_llama_skip.LlamaSkipConnectionForCausalLM'>
Model dtype: torch.float32

Model type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>
Model dtype: torch.float32

SkipLLaMA Scripted CPU Results:
Average time: 0.679s
Min time: 0.407s
Max time: 3.207s
Individual times: ['0.440s', '0.440s', '0.782s', '2.668s', '1.914s', '2.542s', '0.424s', '0.433s', '0.435s', '0.426s', '0.430s', '0.429s', '0.425s', '0.424s', '0.417s', '0.419s', '0.421s', '0.418s', '0.418s', '0.428s', '0.418s', '0.421s', '0.429s', '0.418s', '0.418s', '0.421s', '0.418s', '0.416s', '1.140s', '3.207s', '3.087s', '0.563s', '0.428s', '0.422s', '0.431s', '0.418s', '0.419s', '0.419s', '0.423s', '0.407s', '0.408s', '0.408s', '0.415s', '0.415s', '0.433s', '0.436s', '0.445s', '0.431s', '0.419s']

Standard LLaMA CPU Results:
Average time: 0.964s
Min time: 0.535s
Max time: 4.483s
Individual times: ['0.536s', '0.539s', '0.552s', '2.772s', '1.742s', '3.173s', '0.539s', '0.535s', '0.538s', '0.548s', '0.536s', '0.539s', '0.537s', '0.535s', '0.536s', '0.541s', '0.537s', '0.536s', '0.539s', '0.625s', '0.622s', '0.623s', '0.622s', '0.622s', '4.483s', '1.518s', '2.131s', '0.623s', '0.627s', '0.623s', '0.627s', '0.626s', '0.627s', '0.623s', '0.625s', '0.636s', '0.630s', '0.627s', '0.643s', '0.635s', '0.570s', '0.556s', '0.563s', '1.422s', '3.347s', '2.716s', '1.012s', '0.665s', '0.654s']

CPU Speedups:
Scripted vs Standard: 1.42x
