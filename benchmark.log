Configuring for 8 CPU threads
Model device: cpu
Input IDs device: cpu
Attention Mask device: cpu
Running CPU inference benchmarks...
--------------------------------------------------
Warming up models...

Model type: <class 'src.models.modelling_llama_skip.LlamaSkipConnectionForCausalLM'>
Model dtype: torch.float32

Model type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>
Model dtype: torch.float32

SkipLLaMA Scripted MLP CPU Results:
Average time: 0.009s
Min time: 0.007s
Max time: 0.031s
Individual times: ['0.007s', '0.008s', '0.007s', '0.008s', '0.007s', '0.008s' ]

Standard LLaMA MLP CPU Results:
Average time: 0.028s
Min time: 0.016s
Max time: 0.208s
Individual times: ['0.023s', '0.023s', '0.024s', '0.023s', '0.023s', '0.023s' ]

SkipLLaMA Scripted CPU Results:
Average time: 1.004s
Min time: 0.617s
Max time: 4.241s
Individual times: ['0.627s', '0.639s', '0.617s', '0.624s', '0.627s', '0.674s' ]

Standard LLaMA CPU Results:
Average time: 1.673s
Min time: 1.017s
Max time: 6.059s
Individual times: ['1.399s', '1.391s', '1.374s', '1.376s', '1.377s', '4.746s' ]
CPU Speedups:
Scripted vs Standard: 1.67x
